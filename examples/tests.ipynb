{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continuous-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import mvpy as mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "incorporate-python",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.64108147, 0.03338183],\n",
       "        [0.03338183, 0.75703101]]),\n",
       " array([[0.54986204, 0.07785559],\n",
       "        [0.07785559, 0.82028819]]),\n",
       " array([[0.54986204, 0.07785559],\n",
       "        [0.07785559, 0.82028819]]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class LedoitWolf2:\n",
    "    def __init__(self):\n",
    "        self.covariance_ = None\n",
    "        self.shrinkage_ = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"Fit the Ledoit-Wolf shrinkage estimator to the data X.\"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Compute empirical covariance matrix (unbiased)\n",
    "        X_centered = X - X.mean(axis=0)\n",
    "        S = (X_centered.T @ X_centered) / (n_samples - 1)\n",
    "\n",
    "        # Target: Scaled identity matrix (F)\n",
    "        mu = np.trace(S) / n_features  # Mean of diagonal elements\n",
    "        F = np.eye(n_features) * mu\n",
    "\n",
    "        # Compute shrinkage numerator: Variance of S elements\n",
    "        S_diag = np.diag(S)  # Diagonal elements of S\n",
    "        off_diag_mask = ~np.eye(n_features, dtype=bool)  # Mask for off-diagonal elements\n",
    "        S_off_diag = S[off_diag_mask]  # Extract off-diagonal elements\n",
    "\n",
    "        var_diag = np.var(S_diag, ddof=1)  # Variance of diagonal elements\n",
    "        var_off_diag = np.var(S_off_diag, ddof=1)  # Variance of off-diagonal elements\n",
    "\n",
    "        shrinkage_numerator = var_diag + var_off_diag  # Total variance\n",
    "\n",
    "        # Compute shrinkage denominator: Squared Frobenius norm\n",
    "        frob_norm_sq = np.sum((S - F) ** 2)\n",
    "\n",
    "        # Compute shrinkage coefficient\n",
    "        rho = min(1, shrinkage_numerator / frob_norm_sq)\n",
    "\n",
    "        # Compute Ledoit-Wolf covariance estimate\n",
    "        self.covariance_ = rho * F + (1 - rho) * S\n",
    "        self.shrinkage_ = rho  # Store shrinkage coefficient\n",
    "        return self\n",
    "\n",
    "    def get_covariance(self):\n",
    "        \"\"\"Return the estimated covariance matrix.\"\"\"\n",
    "        return self.covariance_\n",
    "\n",
    "    def get_shrinkage(self):\n",
    "        \"\"\"Return the computed shrinkage coefficient.\"\"\"\n",
    "        return self.shrinkage_\n",
    "\n",
    "class LedoitWolf3:\n",
    "    def __init__(self):\n",
    "        self.covariance_ = None\n",
    "        self.shrinkage_ = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Fit the Ledoit-Wolf shrinkage estimator to the data X.\n",
    "        This implementation exactly follows scikit-learn's procedure.\n",
    "        \"\"\"\n",
    "        \n",
    "        X = np.asarray(X)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Center the data\n",
    "        Xc = X - np.mean(X, axis=0)\n",
    "\n",
    "        # Compute the biased sample covariance matrix (dividing by n_samples)\n",
    "        sample_cov = np.dot(Xc.T, Xc) / n_samples\n",
    "\n",
    "        # Compute the target matrix F = mu * I,\n",
    "        # where mu is the average of the eigenvalues (trace/sample dimension)\n",
    "        mu = np.trace(sample_cov) / n_features\n",
    "        F = mu * np.eye(n_features)\n",
    "\n",
    "        # Compute phi: the sum of the elementwise variances\n",
    "        # First, compute elementwise squared values of the centered data.\n",
    "        X2 = Xc ** 2\n",
    "        # Compute phi_mat as per Ledoit-Wolf:\n",
    "        # (X2.T dot X2) / n_samples - sample_cov**2\n",
    "        phi_mat = np.dot(X2.T, X2) / n_samples - sample_cov ** 2\n",
    "        phi = np.sum(phi_mat)\n",
    "\n",
    "        # Compute gamma: squared Frobenius norm of (sample_cov - F)\n",
    "        gamma = np.linalg.norm(sample_cov - F, 'fro') ** 2\n",
    "\n",
    "        # Compute kappa and then the shrinkage coefficient.\n",
    "        kappa = phi / gamma if gamma != 0 else 0.0\n",
    "        shrinkage = np.clip(kappa / n_samples, 0, 1)\n",
    "\n",
    "        # Compute the shrunk covariance matrix\n",
    "        self.covariance_ = shrinkage * F + (1 - shrinkage) * sample_cov\n",
    "        self.shrinkage_ = shrinkage\n",
    "        return self\n",
    "\n",
    "    def get_covariance(self):\n",
    "        \"\"\"Return the estimated covariance matrix.\"\"\"\n",
    "        return self.covariance_\n",
    "\n",
    "    def get_shrinkage(self):\n",
    "        \"\"\"Return the computed shrinkage coefficient.\"\"\"\n",
    "        return self.shrinkage_\n",
    "\n",
    "real_cov = np.array([[.4, .2],\n",
    "                     [.2, .8]])\n",
    "X = np.random.multivariate_normal(mean=[0, 0],\n",
    "                                  cov=real_cov,\n",
    "                                  size=50)\n",
    "from sklearn.covariance import LedoitWolf\n",
    "cov_a = LedoitWolf2().fit(X)\n",
    "cov_b = LedoitWolf().fit(X)\n",
    "cov_c = LedoitWolf3().fit(X)\n",
    "\n",
    "cov_a.covariance_, cov_b.covariance_, cov_c.covariance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "virtual-persian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "sensitive-server",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6846341850719838, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_b.shrinkage_, cov_a_shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indian-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = 400, 60, 5\n",
    "\n",
    "a = np.random.normal(size = (x, y, z))\n",
    "b = np.random.normal(size = (x, y, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "serial-patrick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923 µs ± 27.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "1.99 ms ± 137 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "3.48 ms ± 157 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "233 ms ± 10.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit d = mv.math.euclidean(a, b)\n",
    "%timeit d = mv.math.cosine(a, b)\n",
    "%timeit d = mv.math.pearsonr(a, b)\n",
    "%timeit d = mv.math.spearmanr(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "seasonal-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "c, d = torch.from_numpy(a).to(torch.float32).to(device), torch.from_numpy(b).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fatal-contact",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648 µs ± 35.5 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "519 µs ± 26.2 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "1.69 ms ± 29 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "196 ms ± 8.1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit r = mv.math.euclidean(c, d)\n",
    "%timeit r = mv.math.cosine(c, d)\n",
    "%timeit r = mv.math.pearsonr(c, d)\n",
    "%timeit r = mv.math.spearmanr(c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "liberal-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'\n",
    "\n",
    "c, d = torch.from_numpy(a).to(torch.float32).to(device), torch.from_numpy(b).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "baking-formula",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181 µs ± 700 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "207 µs ± 5.08 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "466 µs ± 7.97 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "65.2 ms ± 253 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit r = mv.math.euclidean(c, d)\n",
    "%timeit r = mv.math.cosine(c, d)\n",
    "%timeit r = mv.math.pearsonr(c, d)\n",
    "%timeit r = mv.math.spearmanr(c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "under-carol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239 ms ± 1.72 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "123 ms ± 2.62 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "32.5 ms ± 213 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "%timeit scipy.stats.rankdata(a, axis = -1)\n",
    "%timeit mv.math.rank(a)\n",
    "%timeit mv.math.rank(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "structural-promise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02225208282470703\n"
     ]
    }
   ],
   "source": [
    "indx_i = torch.from_numpy(np.arange(x).repeat(x)).to(torch.int32).to(device)\n",
    "indx_j = torch.from_numpy(np.tile(np.arange(x), x)).to(torch.int32).to(device)\n",
    "\n",
    "import time\n",
    "ts = time.time()\n",
    "rdm = mv.math.pearsonr(c[indx_i], c[indx_j])\n",
    "te = time.time()\n",
    "\n",
    "print(te - ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "precious-junior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19900,), (19900,))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = np.arange(x)\n",
    "t1 = np.arange(x)\n",
    "\n",
    "tx, ty = np.meshgrid(t0, t1)\n",
    "cx, cy = np.triu_indices(x, k = 1)\n",
    "indc_i, indc_j = tx.flatten()[cx], ty.flatten()[cy]\n",
    "\n",
    "#indc_i, indc_j = tx.flatten(), ty.flatten()\n",
    "indc_i.shape, indc_j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "center-minneapolis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.2 ms ± 183 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "%timeit mv.math.pearsonr(c[indc_i], c[indc_j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "opened-click",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   2, ..., 197, 198, 199]),\n",
       " array([  0,   0,   0, ..., 199, 199, 199]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indc_i, indc_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cutting-benjamin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdm.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "minimal-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from typing import Union\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "class RSA(sklearn.base.BaseEstimator):\n",
    "    def __init__(self, n_jobs: Union[int, None] = None):\n",
    "        '''\n",
    "        '''\n",
    "        \n",
    "        self.n_jobs = n_jobs\n",
    "    \n",
    "    def fit(self, X: torch.Tensor):\n",
    "        '''\n",
    "        '''\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        '''\n",
    "        \n",
    "        # setup dimensions\n",
    "        dims = X.shape\n",
    "        N, F, T = dims[0], dims[-2], dims[-1]\n",
    "        \n",
    "        # setup indices\n",
    "        n = torch.arange(N)\n",
    "        nx, ny = torch.meshgrid(n, n, indexing = 'ij')\n",
    "        cx, cy = torch.triu_indices(N, N, offset = 1)\n",
    "        i, j = nx.flatten()[cx], ny.flatten()[cy]\n",
    "        \n",
    "        # compute RDM\n",
    "        r = torch.stack(Parallel(n_jobs = self.n_jobs)(delayed(mv.math.euclidean)(c.swapaxes(-2, -1)[i,...,k,:], c.swapaxes(-2, -1)[j,...,k,:]) for k in range(T)), dim = -1)\n",
    "        \n",
    "    def fit_transform(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        '''\n",
    "        \n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "heated-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = c.clone()\n",
    "\n",
    "if True:\n",
    "    if True:\n",
    "        # setup dimensions\n",
    "        dims = X.shape\n",
    "        N, F, T = dims[0], dims[-2], dims[-1]\n",
    "        \n",
    "        # setup indices\n",
    "        n = torch.arange(N)\n",
    "        nx, ny = torch.meshgrid(n, n, indexing = 'ij')\n",
    "        cx, cy = torch.triu_indices(N, N, offset = 1)\n",
    "        i, j = nx.flatten()[cx].to(torch.int32).to(c.device), ny.flatten()[cy].to(torch.int32).to(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "municipal-anthropology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.2 ms ± 418 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "f = mv.math.pearsonr\n",
    "\n",
    "%timeit r = torch.stack([f(c.swapaxes(-2, -1)[i,...,k,:], c.swapaxes(-2, -1)[j,...,k,:]) for k in range(T)], dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "failing-aging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.6 ms ± 563 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "f = mv.math.pearsonr\n",
    "\n",
    "%timeit r = torch.stack([f(c.swapaxes(-2, -1)[i,...,k,:], c.swapaxes(-2, -1)[j,...,k,:]) for k in range(T)], dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "universal-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = torch.stack([f(c.swapaxes(-2, -1)[i,...,k,:], c.swapaxes(-2, -1)[j,...,k,:]) for k in range(T)], dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "atomic-eclipse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([79800, 500]), torch.float32, device(type='mps', index=0))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape, r.dtype, r.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit r = mv.math.cosine(c.swapaxes(-2, -1)[i], c.swapaxes(-2, -1)[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "increasing-electricity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579 ms ± 12 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "n_jobs = 1\n",
    "\n",
    "%timeit r = torch.stack(Parallel(n_jobs = n_jobs)(delayed(mv.math.euclidean)(c.swapaxes(-2, -1)[i,...,k,:], c.swapaxes(-2, -1)[j,...,k,:]) for k in range(T)), dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "prepared-photography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.73 s ± 129 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "n_jobs = 8\n",
    "\n",
    "%timeit r = torch.stack(Parallel(n_jobs = n_jobs)(delayed(mv.math.euclidean)(c.swapaxes(-2, -1)[i,...,k,:], c.swapaxes(-2, -1)[j,...,k,:]) for k in range(T)), dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "industrial-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "RSA(n_jobs = None).fit_transform(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "perceived-forth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484 ms ± 7.31 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit RSA(n_jobs = None).fit_transform(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "naked-syndication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.7 s ± 126 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit RSA(n_jobs = 4).fit_transform(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "whole-citizenship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 10, 100])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.swapaxes(-2, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "educated-decision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1, 1, 1, 2, 2, 3],\n",
       "        [1, 2, 3, 4, 2, 3, 4, 3, 4, 4]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = torch.arange(N)\n",
    "nx, ny = torch.meshgrid(n, n, indexing = 'ij')\n",
    "cx, cy = torch.triu_indices(5, 5, offset = 1)\n",
    "i, j = nx.flatten()[cx], ny.flatten()[cy]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fossil-medication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "prescription-favor",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[200, 200, 50]' is invalid for input of size 995000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mrdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[:,:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[200, 200, 50]' is invalid for input of size 995000"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(rdm.reshape((x, x, y))[:,:,0].cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sempriors",
   "language": "python",
   "name": "sempriors"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
