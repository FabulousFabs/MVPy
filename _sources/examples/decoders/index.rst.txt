

.. _sphx_glr_examples_decoders:


Decoders
========
Examples for decoders.


.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We will begin our look at decoders by using an MEG dataset of humans performing a visual categorization task. Briefly, participants saw a list of 92 images. Here, we will only use 24 of these images, either of faces or not faces. For more information, consult MNE&#x27;s documentation &lt;https://mne.tools/1.8/auto_examples/decoding/decoding_rsa_sgskip.html&gt; or the original paper &lt;https://dx.doi.org/10.1038/nn.3635&gt;.">

.. only:: html

  .. image:: /examples/decoders/images/thumb/sphx_glr_decoders_intro_thumb.png
    :alt:

  :ref:`sphx_glr_examples_decoders_decoders_intro.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Decoders</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /examples/decoders/decoders_intro

