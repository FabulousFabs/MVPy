

.. _sphx_glr_examples_decoders:


Decoders
========
Examples for decoders.


.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We will begin our look at decoders by using an MEG dataset of humans performing a visual categorization task. Briefly, participants saw a list of 92 images. Here, we will only use 24 of these images, either of faces or not faces. For more information, consult MNE&#x27;s documentation or the original paper.">

.. only:: html

  .. image:: /examples/decoders/images/thumb/sphx_glr_1_decoders_intro_thumb.png
    :alt:

  :ref:`sphx_glr_examples_decoders_1_decoders_intro.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">1. Classification</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /examples/decoders/1_decoders_intro

