{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 1. Classification\n\nWe will begin our look at decoders by using an MEG dataset of humans performing a visual categorization task. Briefly, participants saw a list of 92 images. Here, we will only use 24 of these images, either of faces or not faces. For more information, consult [MNE's documentation](https://mne.tools/1.8/auto_examples/decoding/decoding_rsa_sgskip.html) or the [original paper](https://dx.doi.org/10.1038/nn.3635).\n\nFor convenience, we will consider only gradiometer channels from the dataset, though you are free to change this, of course. The goal will be to build a classifier that can distinguish between faces/not-faces.\n\nFirst, we will have to load the data---To do this, we use MNE's sample code. Be aware that this will download roughly 6GB of data, which may take a while.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nfrom pandas import read_csv\nimport matplotlib.pyplot as plt\n\nimport mne\nfrom mne.datasets import visual_92_categories\nfrom mne.io import concatenate_raws, read_raw_fif\n\nprint(__doc__)\n\ndata_path = visual_92_categories.data_path()\n\n# Define stimulus - trigger mapping\nfname = data_path / \"visual_stimuli.csv\"\nconds = read_csv(fname)\nprint(conds.head(5))\n\nmax_trigger = 24\nconds = conds[:max_trigger]  # take only the first 24 rows\n\nconditions = []\nfor c in conds.values:\n    cond_tags = list(c[:2])\n    cond_tags += [\n        (\"not-\" if i == 0 else \"\") + conds.columns[k] for k, i in enumerate(c[2:], 2)\n    ]\n    conditions.append(\"/\".join(map(str, cond_tags)))\nprint(conditions[:10])\n\nevent_id = dict(zip(conditions, conds.trigger + 1))\nevent_id[\"0/human bodypart/human/not-face/animal/natural\"]\n\nn_runs = 4  # 4 for full data (use less to speed up computations)\nfnames = [data_path / f\"sample_subject_{b}_tsss_mc.fif\" for b in range(n_runs)]\nraws = [\n    read_raw_fif(fname, verbose=\"error\", on_split_missing=\"ignore\") for fname in fnames\n]  # ignore filename warnings\nraw = concatenate_raws(raws)\n\nevents = mne.find_events(raw, min_duration=0.002)\n\nevents = events[events[:, 2] <= max_trigger]\n\npicks = mne.pick_types(raw.info, meg=True)\nepochs = mne.Epochs(\n    raw,\n    events=events,\n    event_id=event_id,\n    baseline=None,\n    picks='grad',\n    tmin=-0.1,\n    tmax=0.500,\n    preload=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have succesfully loaded the data, we will quickly bring the data into a format that we can work with (i.e., arrays) and produce a vector of target labels as well:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_nf = epochs['not-face'].get_data(picks = 'grad') # grab data from not-face epochs\nX_if = epochs['face'].get_data(picks = 'grad') # grab data from face epochs\n\n# concatenate the data to make it easy to label\n# i.e., data is (trials, channels, time)\nX = np.concatenate((X_nf, X_if), axis = 0)\n\n# create labels\ny = [0] * 360 + [1] * 360\n\n# for model fitting, we want labels to match the dimensions of our data, i.e. (trials, channels, time)\ny = np.array(y)[:,None,None] * np.ones((X.shape[0], 1, X.shape[-1]))\n\nprint(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have our data in a nicely structured format, let's look at building our classifier. We will build our classifier using torch. Consequently, we will begin by transforming our data to torch tensors. Note that, if you have a GPU, you may also specify a different device than 'cpu' here.\n Next, we will create a relatively standard pipeline using a combination of MVPy estimators and sklearn utilities.\n%%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom mvpy.estimators import Scaler, Covariance, Sliding, Classifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import StratifiedKFold\n\n# transform our data to torch on specified device\ndevice = 'cpu' # if desired, change your device here\nX_tr, y_tr = torch.from_numpy(X).to(torch.float32).to(device), torch.from_numpy(y).to(torch.float32).to(device)\n\n# define our cross-validation scheme\nn_splits = 5\nskf = StratifiedKFold(n_splits = n_splits)\n\n# define our classifier pipeline:\n#    1. Apply a standard scaling to our data to ensure that all features are on the same scale\n#    2. Compute the covariance matrix of our data and use it to whiten our data.\n#    3. Create a sliding estimator that will slide a classifier over the dimension of time for us. We also specify a range of alpha values for our Classifier to test, of course.\npipeline = make_pipeline(Scaler().to_torch(),\n                         Covariance(method = 'LedoitWolf').to_torch(),\n                         Sliding(Classifier(torch.logspace(-5, 10, 20)),\n                                 dims = torch.tensor([-1]),\n                                 n_jobs = None,\n                                 verbose = True))\n\n# setup our output data structures: out-of-sample accuracy, and the patterns the classifier used.\noos = torch.zeros((n_splits, X.shape[-1]), dtype = X_tr.dtype, device = X_tr.device) # (folds, time points)\npatterns = torch.zeros((n_splits, X.shape[1], X.shape[-1]), dtype = X_tr.dtype, device = X_tr.device) # (folds, channels, time points)\n\n# loop over cross-validation folds\nfor f_i, (train, test) in enumerate(skf.split(X_tr[:,0,0], y_tr[:,0,0])):\n    # fit model\n    pipeline.fit(X_tr[train], y_tr[train])\n    \n    # score model\n    y_h = pipeline.predict(X_tr[test])\n    oos[f_i] = (y_h[:,None,:] == y_tr[test]).to(torch.float32).mean((0, 1))\n    \n    # obtain pattern\n    pattern = pipeline[2].collect('pattern_')\n    pattern = torch.linalg.inv(pipeline[1].whitener_) @ pattern\n    pattern = pipeline[0].inverse_transform(pattern[:,:,0].T[None,:,:])\n    patterns[f_i] = pattern.squeeze()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once we have fit our model, we may now wish to look at how well it performed. Let's do so now.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nt = np.arange(-0.1, 0.5 + 1e-3, 1e-3) # epochs range from -100ms to +500ms\nax.plot(t, [0.5] * oos.shape[-1], color = 'red', label = 'chance') # plot chance-level\nax.plot(t, oos.cpu().numpy().mean(axis = 0), label = 'classifier') # plot classifier performance\nax.set_ylabel(r'Accuracy')\nax.set_xlabel(r'Time (s)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we would also like to visualise the patterns that the classifier used. Let's visualise this briefly using MNE:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parray = mne.EpochsArray(patterns, info = epochs.info).average()\nparray.plot_topomap(ch_type = \"grad\");"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}